# Go Boilerplate

[![CI](https://github.com/chud-lori/go-boilerplate/actions/workflows/ci.yaml/badge.svg)](https://github.com/chud-lori/go-boilerplate/actions/workflows/ci.yaml)
[![Go Report Card](https://goreportcard.com/badge/github.com/chud-lori/go-boilerplate)](https://goreportcard.com/report/github.com/chud-lori/go-boilerplate)
![Go Version](https://img.shields.io/badge/go-1.23+-blue)
![License](https://img.shields.io/github/license/chud-lori/go-boilerplate)

A modern, production-ready Go boilerplate for building scalable web APIs and microservices. This project follows Clean Architecture principles and includes best practices for modularity, testing, observability, and maintainability.

---

## âœ¨ Features

- **Clean Architecture**: Separation of concerns with domain, adapters, and infrastructure layers.
- **REST API**: User CRUD endpoints with DTOs, controllers, and routing.
- **gRPC Support**: Example gRPC service (Mail) with protobuf definitions and testable client/server.
- **Circuit Breaker Pattern**: Resilient external service communication using [gobreaker](https://github.com/sony/gobreaker) for both HTTP API and gRPC clients.
- **Caching (Redis)**: In-memory caching with Redis through a Cache interface for performance optimization.
- **Pessimistic Locking (Redis)**: Distributed pessimistic locking using Redis to ensure data consistency in concurrent operations.
- **PostgreSQL Integration**: Repository pattern with transaction support, migrations, and test containers for DB testing.
- **Database Migrations**: Built-in support with [golang-migrate](https://github.com/golang-migrate/migrate).
- **Middleware**: Logging, API key authentication, and request context propagation.
- **Logging**: Structured logging with Logrus, configurable log levels.
- **Error Handling**: Centralized error types and helpers.
- **Testing**: Extensive unit and integration tests with mocks and test containers.
- **Dockerized**: Dockerfile and docker-compose.yml for local development and deployment.
- **Observability**: Loki/Promtail/Grafana stack for log aggregation and visualization.
- **Swagger Docs**: Built-in support for Swagger API documentation with [Swag CLI](https://github.com/swaggo/swag).
- **Asynchronous Processing (RabbitMQ)**: Decoupled background job processing for tasks like file uploads, using RabbitMQ and a JobQueue abstraction.
- **Server-Sent Events (SSE)**: Real-time streaming of async job status (e.g., upload progress) to clients via SSE endpoints.

---

## ðŸ—‚ï¸ Project Structure

```
â”œâ”€â”€ adapters/Â  Â  Â  Â  Â  Â  Â  Â  Â  # Interfaces connecting the app to the outside world
â”‚Â  Â â”œâ”€â”€ controllers/Â  Â  Â  Â  Â  Â # HTTP handlers implementing input ports
â”‚Â  Â â”œâ”€â”€ middleware/Â  Â  Â  Â  Â  Â  # HTTP middleware (e.g., logging, API key auth)
â”‚Â  Â â”œâ”€â”€ repositories/Â  Â  Â  Â  Â  # DB implementation of domain repositories
â”‚Â  Â â””â”€â”€ web/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Web utilities including DTOs and helpers
â”‚Â  Â  Â  Â â”œâ”€â”€ dto/Â  Â  Â  Â  Â  Â  Â  Â # Request/response DTO structs
â”‚Â  Â  Â  Â â”œâ”€â”€ helper/Â  Â  Â  Â  Â  Â  # Helper functions for the web layer (includes SSE helpers)
â”‚Â  Â  Â  Â â””â”€â”€ routes.goÂ  Â  Â  Â  Â  # HTTP route registration
â”‚
â”œâ”€â”€ cmd/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Application entry points
â”‚Â  Â â”œâ”€â”€ api/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Main REST API entry point
â”‚Â  Â â”œâ”€â”€ grpcserver/Â  Â  Â  Â  Â  Â  # Main gRPC mail server entry point
â”‚Â  Â â””â”€â”€ upload_consumer/Â  Â  Â  Â  # Background worker for async uploads (RabbitMQ consumer)
â”‚
â”œâ”€â”€ config/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Application configuration loading and parsing
â”‚
â”œâ”€â”€ docs/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Swagger documentation (auto-generated)
â”‚
â”œâ”€â”€ domain/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Core business logic layer (Clean Architecture)
â”‚Â  Â â”œâ”€â”€ entities/Â  Â  Â  Â  Â  Â  Â  # Domain entities (e.g., User, Post)
â”‚Â  Â â”œâ”€â”€ ports/Â  Â  Â  Â  Â  Â  Â  Â  Â # Interfaces for controllers, services, repos, etc.
â”‚Â  Â â””â”€â”€ services/Â  Â  Â  Â  Â  Â  Â  # Application use case implementations
â”‚
â”œâ”€â”€ infrastructure/Â  Â  Â  Â  Â  Â # External infrastructure implementations
â”‚Â  Â â”œâ”€â”€ api_clients/Â  Â  Â  Â  Â   # HTTP API clients with circuit breaker
â”‚Â  Â â”œâ”€â”€ cache/Â  Â  Â  Â  Â  Â  Â  Â   # Redis cache implementation
â”‚Â  Â â”œâ”€â”€ datastore/Â  Â  Â  Â  Â  Â   # PostgreSQL DB setup and connection logic
â”‚Â  Â â”œâ”€â”€ grpc_clients/Â  Â  Â  Â  Â  # gRPC clients used by the application
â”‚Â   â””â”€â”€ locking/Â  Â  Â  Â  Â       # Pessimistic locking using redis
â”‚Â  Â â””â”€â”€ queue/                # RabbitMQ job queue implementation
â”‚
â”œâ”€â”€ internal/Â  Â  Â  Â  Â  Â  Â  Â  Â # Internal packages
â”‚Â  Â â”œâ”€â”€ testutils/Â  Â  Â  Â  Â  Â  Â # Helpers and setup for tests
â”‚Â  Â â””â”€â”€ utils/Â  Â  Â  Â  Â  Â  Â  Â  Â # Internal utilities (e.g., graceful shutdown)
â”‚
â”œâ”€â”€ migrations/Â  Â  Â  Â  Â  Â  Â  Â # SQL migration files for golang-migrate
â”‚
â”œâ”€â”€ mocks/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Mocks for interfaces used in unit tests
â”‚
â”œâ”€â”€ pkg/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Reusable utilities across layers
â”‚Â  Â â”œâ”€â”€ auth/Â  Â  Â  Â  Â  Â  Â  Â  Â  # Encryption, JWT, and passcode helpers
â”‚Â  Â â”œâ”€â”€ errors/Â  Â  Â  Â  Â  Â  Â  Â  # Custom error definitions and validation logic
â”‚Â  Â â””â”€â”€ logger/Â  Â  Â  Â  Â  Â  Â  Â  # Logrus setup and logger abstraction
â”‚
â”œâ”€â”€ proto/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Generated protobuf files for gRPC
â”‚
â”œâ”€â”€ DockerfileÂ  Â  Â  Â  Â  Â  Â  Â  # Docker build instructions for API service
â”œâ”€â”€ docker-compose.ymlÂ  Â  Â  Â  # Docker Compose for service orchestration
â”œâ”€â”€ grafana-datasources.ymlÂ  Â # Grafana configuration for Loki
â”œâ”€â”€ init.sqlÂ  Â  Â  Â  Â  Â  Â  Â  Â  # Optional DB init script for Postgres service
â”œâ”€â”€ mail.protoÂ  Â  Â  Â  Â  Â  Â  Â  # Protobuf definition for gRPC Mail service
â”œâ”€â”€ MakefileÂ  Â  Â  Â  Â  Â  Â  Â  Â  # Developer automation (build, run, test)
â”œâ”€â”€ promtail.ymlÂ  Â  Â  Â  Â  Â  Â  # Promtail config for log shipping to Loki
â”œâ”€â”€ .env.exampleÂ  Â  Â  Â  Â  Â  Â  # Example environment variables file
â”œâ”€â”€ go.modÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Go module definition
â”œâ”€â”€ go.sumÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Go module checksums
â”œâ”€â”€ LICENSEÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â # License information
â””â”€â”€ readme.mdÂ  Â  Â  Â  Â  Â  Â  Â  Â # Project documentation (youâ€™re here!)
```

---

## ðŸš€ Getting Started

### Prerequisites

- Go 1.23+
- Docker & Docker Compose
- **k6**: For running load tests. [Install k6](https://k6.io/docs/getting-started/installation/)

---

### ðŸ§‘â€ðŸ’» Local Development

1. **Clone the repo**

2. **Configure environment variables**

```sh
cp .env.example .env
```

3. **Start services**

```sh
make up
```

4. **API Endpoints**
   - REST: `POST /api/user`, `PUT /api/user/{userId}`, etc.
   - gRPC: See [`cmd/grpcserver/`](cmd/grpcserver/) and [`mail.proto`](mail.proto)

5. **Swagger Docs**

```sh
make swagger
```

Access at: [http://localhost:8080/docs/index.html](http://localhost:8080/docs/index.html)

> ðŸ’¡ Tip: You can use this Node.js command to generate a `JWT_SECRET`:

```sh
node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
```

---

### âš¡ï¸ Running the gRPC Mail Server

> **Note:** The Auth service now sends mail using gRPC and expects a mail gRPC server running at `localhost:50051`.
> You must start the gRPC mail server for the boilerplate to function correctly.

#### 1. Start the gRPC Mail Server

Run the gRPC Server using this command:

```sh
go run cmd/grpcserver/main.go
```

Or, using Makefile:

```sh
make run-grpc
```

#### 2. Confirm the server is running

The gRPC server should listen on `localhost:50051`.
The Auth service will connect to this address to send mail.

---

### âš¡ï¸ Running the Upload Consumer (Async Worker)

> **Note:** The upload consumer service processes background jobs (e.g., file uploads) from RabbitMQ. You must start the upload consumer for async uploads to work.

#### 1. Start the Upload Consumer

Run the consumer using this command:

```sh
go run cmd/upload_consumer/main.go
```

Or, using Makefile (if available):

```sh
make run-upload-consumer
```

#### 2. Confirm the consumer is running

The upload consumer will listen for jobs on RabbitMQ and update upload statuses in Redis.

---

## âš¡ï¸ Asynchronous Processing (RabbitMQ)

This boilerplate supports asynchronous/background job processing using RabbitMQ. This is useful for tasks like file uploads, notifications, or any long-running process that should not block API requests.

- **Abstraction**: The `JobQueue` interface (`domain/ports/job_queue.go`) allows for easy swapping of queue backends.
- **Implementation**: `infrastructure/queue/rabbitmq.go` provides a RabbitMQ-based implementation.
- **Worker**: The `cmd/upload_consumer/` service consumes jobs from RabbitMQ and processes uploads in the background.
- **Usage Example**: When a user uploads a file to a post, the API enqueues the upload job and returns an `upload_id` immediately. The upload is processed asynchronously.

---

## ðŸ“¡ Real-Time Status with Server-Sent Events (SSE)

The boilerplate exposes an SSE endpoint to stream the status of asynchronous jobs (such as file uploads) to clients in real time.

- **SSE Helper**: `adapters/web/helper/sse.go` provides a reusable SSE handler.
- **Endpoint**: `GET /api/uploads/{uploadId}/events` streams status updates for a given upload.
- **How it works**: The client subscribes to this endpoint using EventSource or similar, and receives status updates (e.g., `pending`, `uploading`, `success`, `failed`).

**Example Usage:**

1. **Start an async upload:**
    ```http
    POST /api/post/{postId}/upload
    Content-Type: multipart/form-data
    ...
    -> Response: { "upload_id": "..." }
    ```
2. **Subscribe to status updates:**
    ```js
    const source = new EventSource('/api/uploads/{upload_id}/events');
    source.onmessage = (event) => {
      console.log('Upload status:', event.data); // e.g., 'pending', 'uploading', 'success', 'failed'
    };
    ```

---

## ðŸ³ Running with Docker

1. **Create Docker environment file**

```sh
cp .env.example .env.docker
```

2. **Edit `.env.docker`** to set environment variables for Docker deployment:

```env
DB_NAME=service_db
PSQL_USER=postgres
PSQL_PASSWORD=root
DATABASE_URL=postgres://postgres:root@service-postgres:5432/service_db?sslmode=disable
REDIS_URL=redis://service-redis:6379
RABBITMQ_URL=amqp://user:password@service-rabbitmq:5672/
```

3. **Start containers**

```sh
docker-compose up --build
```

> ðŸ“ `.env.docker` will be used by `docker-compose.yml` via the `env_file` section.
> The app will treat it as `.env` at runtime.
> The following services will be started:
> - API server
> - gRPC mail server
> - Redis
> - PostgreSQL
> - RabbitMQ (with management UI at [http://localhost:15672](http://localhost:15672), default user: `user`, password: `password`)
> - Upload consumer (background worker for async jobs)

---

## ðŸ§ª Running Tests

```sh
make test
```

- Unit tests for services and helpers
- Integration tests using [testcontainers-go](https://github.com/testcontainers/testcontainers-go) for PostgreSQL and Redis

---

## ðŸ“ˆ Performance Testing (k6)

This boilerplate includes a k6 script for load testing the REST API endpoints. This helps in understanding the system's performance and stability under various loads.

1.  **Ensure k6 is installed** (see [Prerequisites](#prerequisites)).
2.  **Make sure the Go API service is running** (e.g., via `make up` or `docker-compose up --build`).
3.  **Run the k6 script**:
    ```sh
    k6 run loadtest.js
    ```
    This script simulates a user flow including:
    * Creating a new post (`POST /api/post`)
    * Fetching posts twice (`GET /api/post`)

    Adjust the `vus`